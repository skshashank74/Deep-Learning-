{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvqBi4iF8BtA"
   },
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0LmZumh8ErN"
   },
   "source": [
    "## Problem 1: Network Compression Using SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zx7VJhyARjN"
   },
   "source": [
    "1. Train a fully-connected net for MNIST classification. It should be with 5 hidden layers each of which is with 1024 hidden units. Feel free to use whatever techniques you learned in class. You should be able to get the test accuracy above 98%. Let’s call this network “baseline”. You can reuse the one from the previous homework if its accuracy is good enough. Otherwise, this would be a good chance for you to improve your “baseline” MNIST classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "sx8HRqJl9eiP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import imshow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XfiifB--ba5",
    "outputId": "aa63498b-369d-4f86-e55a-7014790a24aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61S1-RjsAq3E"
   },
   "source": [
    "#### Data load and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wj6_bhce_4-r",
    "outputId": "9b119513-14c9-40ac-a586-cc88eaeaa9fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# reshaping the data\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# normalizing the data\n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0\n",
    "\n",
    "# converting labels to categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u5d2mnHAwDH"
   },
   "source": [
    "#### Model Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrKEiq06AppY",
    "outputId": "67027558-3b7b-4410-b6a9-1e2b566eb5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1024)              803840    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,012,490\n",
      "Trainable params: 5,012,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "he_initializer=tf.keras.initializers.HeNormal()\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim = 784, activation='relu', kernel_initializer=he_initializer))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer=he_initializer))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer=he_initializer))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer=he_initializer))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer=he_initializer))\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer=he_initializer))\n",
    "\n",
    "#from keras.optimizers import Adam\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFdSxvGjA4JV"
   },
   "source": [
    "#### Fitting on train and predicting on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02AKMMQIB_xy",
    "outputId": "84204402-2688-452a-e235-f4e7731389af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0612 - accuracy: 0.8924 - val_loss: 0.0202 - val_accuracy: 0.9633\n",
      "Epoch 2/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0154 - accuracy: 0.9748 - val_loss: 0.0153 - val_accuracy: 0.9735\n",
      "Epoch 3/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0093 - accuracy: 0.9847 - val_loss: 0.0148 - val_accuracy: 0.9759\n",
      "Epoch 4/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9892 - val_loss: 0.0143 - val_accuracy: 0.9774\n",
      "Epoch 5/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9906 - val_loss: 0.0196 - val_accuracy: 0.9715\n",
      "Epoch 6/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9923 - val_loss: 0.0135 - val_accuracy: 0.9800\n",
      "Epoch 7/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9941 - val_loss: 0.0131 - val_accuracy: 0.9804\n",
      "Epoch 8/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9942 - val_loss: 0.0177 - val_accuracy: 0.9772\n",
      "Epoch 9/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9950 - val_loss: 0.0128 - val_accuracy: 0.9819\n",
      "Epoch 10/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9950 - val_loss: 0.0139 - val_accuracy: 0.9813\n",
      "Epoch 11/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.9969 - val_loss: 0.0220 - val_accuracy: 0.9720\n",
      "Epoch 12/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9956 - val_loss: 0.0180 - val_accuracy: 0.9764\n",
      "Epoch 13/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9964 - val_loss: 0.0153 - val_accuracy: 0.9799\n",
      "Epoch 14/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9972 - val_loss: 0.0153 - val_accuracy: 0.9828\n",
      "Epoch 15/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.9969 - val_loss: 0.0161 - val_accuracy: 0.9815\n",
      "Epoch 16/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9965 - val_loss: 0.0161 - val_accuracy: 0.9797\n",
      "Epoch 17/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.9968 - val_loss: 0.0162 - val_accuracy: 0.9787\n",
      "Epoch 18/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.9968 - val_loss: 0.0140 - val_accuracy: 0.9827\n",
      "Epoch 19/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9981 - val_loss: 0.0146 - val_accuracy: 0.9838\n",
      "Epoch 20/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9971 - val_loss: 0.0135 - val_accuracy: 0.9842\n",
      "Epoch 21/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 0.9978 - val_loss: 0.0162 - val_accuracy: 0.9830\n",
      "Epoch 22/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 0.9980 - val_loss: 0.0143 - val_accuracy: 0.9834\n",
      "Epoch 23/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.9975 - val_loss: 0.0132 - val_accuracy: 0.9841\n",
      "Epoch 24/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9983 - val_loss: 0.0175 - val_accuracy: 0.9835\n",
      "Epoch 25/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 8.8673e-04 - accuracy: 0.9987 - val_loss: 0.0135 - val_accuracy: 0.9837\n",
      "Epoch 26/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9979 - val_loss: 0.0165 - val_accuracy: 0.9841\n",
      "Epoch 27/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9978 - val_loss: 0.0138 - val_accuracy: 0.9844\n",
      "Epoch 28/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 9.8663e-04 - accuracy: 0.9987 - val_loss: 0.0183 - val_accuracy: 0.9821\n",
      "Epoch 29/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9983 - val_loss: 0.0169 - val_accuracy: 0.9823\n",
      "Epoch 30/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 0.9984 - val_loss: 0.0168 - val_accuracy: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa76618cad0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "history = History()\n",
    "model.fit(x_train, y_train, epochs=30, batch_size=512, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WsmR2LBhApkg"
   },
   "outputs": [],
   "source": [
    "model.save_weights('/content/drive/MyDrive/Deep Learning Assignment/mnsit_weights',save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iqMcQ9VmcJoT"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/MyDrive/Deep Learning Assignment/mnsit_weights',by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgENPK9NByNr"
   },
   "source": [
    "#### Accuracy on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jVyucSWPCHKs",
    "outputId": "92252061-6b5c-4ca4-a04e-c12747d2db77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 0.9814\n",
      "Accuracy on test data: 98.14\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(x_test, y_test )\n",
    "print('Accuracy on test data: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZAGq0xDBPsE"
   },
   "source": [
    "2. You learned that Singular Value Decomposition (SVD) can compress the weight matrices (Module\n",
    "6). You have 6 different weight matrices in your baseline network, i.e. W (1) ∈ R784×1024, W (2) ∈ R1024×1024 , · · · , W (5) ∈ R1024×1024 , W (6) ∈ R1024×10 . Run SVD on each of them, except for W (6) which is too small already, to approximate the weight matrices: For this, feel free to use whatever implementation you can find. tf.svd or torch.svd will serve the purpose. Note that we don’t compress bias (just because we’re lazy).\n",
    "\n",
    "3. If you look into the singular value matrix S(l), it should be a diagonal matrix. Its values are sorted in the order of their contribution to the approximation. What that means is that you can discard the least important singular values by sacrificing the approximation performance. For example, if you choose to use only D singular values and if the singular values are sorted in the descending order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnE3I_vHCTyT"
   },
   "source": [
    "### SVD on each layers of weights and then replacing the weight by the decomposition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "c51CbCobOfDm"
   },
   "outputs": [],
   "source": [
    "# Storing the weights\n",
    "weights = []\n",
    "bias = []\n",
    "for i in range(6):\n",
    "  weights.append(model.layers[i].get_weights()[0])\n",
    "  bias.append(model.layers[i].get_weights()[1])\n",
    "\n",
    "# initializing s,u,v\n",
    "s,u,v =[[]], [[]],[[]]\n",
    "for i in range(4):\n",
    "  s.append([])\n",
    "  u.append([])\n",
    "  v.append([])\n",
    "\n",
    "# SVD\n",
    "def svd(mat):\n",
    "  s, u, v = tf.linalg.svd(mat,full_matrices=False,compute_uv=True,name=None)\n",
    "  return s, u, v\n",
    "\n",
    "# doing svd for each weights\n",
    "for i in range(5):\n",
    "  s[i],u[i],v[i] = svd(weights[i])\n",
    "\n",
    "\n",
    "# setting the weights in the model\n",
    "def set_weights_layers(D, Full = False):\n",
    "  for i in range(6):\n",
    "    if i == 5:\n",
    "      model.layers[i].set_weights((weights[i],bias[i]))\n",
    "    elif Full == True and i == 0:\n",
    "      W = tf.matmul(u[i][:,:784], tf.matmul(tf.linalg.diag(s[i][:784]), v[i][:,:784], adjoint_b=True))\n",
    "      model.layers[i].set_weights((W,bias[i]))\n",
    "    else:\n",
    "      W = tf.matmul(u[i][:,:D], tf.matmul(tf.linalg.diag(s[i][:D]), v[i][:,:D], adjoint_b=True))\n",
    "      model.layers[i].set_weights((W,bias[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF_SFfXLC1Nn"
   },
   "source": [
    "4. Vary your D from 10, 20, 50, 100, 200, to Dfull, where Dfull is the original size of S(l) (so D = Dfull means you use (1) instead of (2)). For example, Dfull = 784 when l = 1 and 1024 when l > 1. Now you have 6 differently compressed versions that are using W􏰄 for feedforward. Each 6 networks are\n",
    "using one of the 6 D values of your choice. Report the test accuracy of the six approximated networks (perhaps a graph whose x-axis is D and y-axis is the test accuracy). You’ll see that when D = Dfull the test accuracy is almost as good as the baseline, while D = 10 will give you the worst performance. Note, however, that D = Dfull doesn’t give you any compression, while smaller choices of D can reduce the amount of computation during feedforward.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9fElFmBDFaI"
   },
   "source": [
    "#### Varying D =10, 20, 50, 100, 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSwr2EhwQOTf"
   },
   "source": [
    "#### D = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdQDN7FHQNYC",
    "outputId": "cdae2a53-189b-40c0-a511-0d91902869ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3822 - accuracy: 0.6430\n",
      "Accuracy on the test data: 64.30\n"
     ]
    }
   ],
   "source": [
    "set_weights_layers(10)\n",
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy_10 = model.evaluate(x_test, y_test )\n",
    "print('Accuracy on the test data: %.2f' % (accuracy_10*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0_gmzimQayK"
   },
   "source": [
    "#### D = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0yIUIL6QR88",
    "outputId": "b1173273-5dab-4d8a-a078-d9e79f54ea22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9126\n",
      "Accuracy on the test data: 91.26\n"
     ]
    }
   ],
   "source": [
    "set_weights_layers(20)\n",
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy_20 = model.evaluate(x_test, y_test )\n",
    "print('Accuracy on the test data: %.2f' % (accuracy_20*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7X2-IObEQlin"
   },
   "source": [
    "#### D = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fTE6NbfQcnI",
    "outputId": "f51f436b-2cd4-462a-e045-8613fb43bba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0182 - accuracy: 0.9781\n",
      "Accuracy: 97.81\n"
     ]
    }
   ],
   "source": [
    "set_weights_layers(50)\n",
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy_50 = model.evaluate(x_test, y_test )\n",
    "print('Accuracy on the test data: %.2f' % (accuracy_50*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW9obJstQo8Q"
   },
   "source": [
    "#### D= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJEEIgRJQh8L",
    "outputId": "369e37cd-e255-40b9-a4c4-71c66a58870f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0158 - accuracy: 0.9821\n",
      "Accuracy: 98.21\n"
     ]
    }
   ],
   "source": [
    "set_weights_layers(100)\n",
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy_100 = model.evaluate(x_test, y_test )\n",
    "print('Accuracy on the test data: %.2f' % (accuracy_100*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ystf9SCEai_P"
   },
   "source": [
    "#### D = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Sq5FvStaePT",
    "outputId": "9d3bcf52-0d99-49be-8e83-2f7b52d6177f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0159 - accuracy: 0.9828\n",
      "Accuracy on the test data: 98.28\n"
     ]
    }
   ],
   "source": [
    "set_weights_layers(500)\n",
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy_500 = model.evaluate(x_test, y_test )\n",
    "print('Accuracy on the test data: %.2f' % (accuracy_500*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZGa_LuPE1Ok"
   },
   "source": [
    "#### D = Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K01pCyhDD7sF",
    "outputId": "813d851e-dcc3-4bcf-8ff7-7a39e8500abf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0159 - accuracy: 0.9828\n",
      "Accuracy on the test data: 98.28\n"
     ]
    }
   ],
   "source": [
    "set_weights_layers(1024, Full= True)\n",
    "_, accuracy_full = model.evaluate(x_test, y_test )\n",
    "print('Accuracy on the test data: %.2f' % (accuracy_full*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIv4yTQEGVwk"
   },
   "source": [
    "5. Report your test accuracies of the six SVDed versions along with your baseline performance. Report the number of parameters of your SVDed networks and compare them to the baseline’s. Be careful with the S(l) matrices: they are diagonal matrices, meaning that there are only D nonzero elements.\n",
    "\n",
    "6. Note that you don’t have to run the SVD algorithm multiple times to vary D. Run it once, and extract different versions by varying D. That’s what’s good about SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "4ygL4tdAGWSN"
   },
   "outputs": [],
   "source": [
    "accuracy = [accuracy_10,accuracy_20,accuracy_50,accuracy_100,accuracy_500,accuracy_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "zs4Lwo9LGkFp"
   },
   "outputs": [],
   "source": [
    "D = ['10','20','50','100','500','Full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "J5gxz3CSGVAw",
    "outputId": "c64f366d-3cc3-40dd-f620-8b06754dcc7e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(D, accuracy)\n",
    "plt.xlabel('Test Accuracy')\n",
    "plt.ylabel('Dimensions considered in SVD')\n",
    "plt.title('Model Performance')\n",
    "\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FA6JbtzgKct_"
   },
   "source": [
    "##### Number of Parameters\n",
    "\n",
    "$ Parameter = no. of \\,input node * output\\, nodes + bias\\, nodes $ \n",
    "\n",
    "We can see the number of paramaters of each layer in model.summary. In total it uses 5012490 paramters\n",
    "\n",
    "When we decompose the matrix into multiple D, we now only need to store D dimension to reconstruct the W back. \n",
    "\n",
    "D - 10\n",
    "Params = $ 10*1024 + 10*1024 +10*1024 +10*1024 +10*1024 +10*1024 + 5*1024 (bias of five layers) = 66260$\n",
    "\n",
    "D - 20\n",
    "Params = $ 20*1024 + 20*1024 +20*1024 +20*1024 +20*1024 +10*1024 + 5*1024 = 117760$\n",
    "\n",
    "D - 50\n",
    "Params = $ 50*1024 + 50*1024 +50*1024 +50*1024 +50*1024 +10*1024  + 5*1024= 271360$\n",
    "\n",
    "D - 100\n",
    "Params = $ 100*1024 + 100*1024 +100*1024 +100*1024 +100*1024 +10*1024 + 5*1024= 527360$\n",
    "\n",
    "D - 500\n",
    "Params = $ 500*1024 + 500*1024 +500*1024 +500*1024 +500*1024 +10*1024 + 5*1024= 2575360$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8A21ap1L3eq",
    "outputId": "0ef39539-00f5-4203-8e2e-8f3617050bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 1024)              803840    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,012,490\n",
      "Trainable params: 5,012,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6mKcOjXb_Di"
   },
   "source": [
    "## Problem 2: Network Compression Using SVD \n",
    "\n",
    "1. Now you learned that the low rank approximation of W (l) gives you some compression. However, you might not like the performance of the too small D values. From now on, fix your D = 20 and let’s improve its performance.\n",
    "\n",
    "2. Define a NEW network whose weight matrices W (l) are factorized. Again, this is a new one, different from your baseline in P1. In this new network, you don’t estimate W(l) directly anymore, but its\n",
    "factor matrices, to reconstruct W(l) as follows: W(l) = U(l)V(l)⊤.\n",
    "\n",
    "5. Again, note that U and V are the new variables that you need to estimate via optimization. They are fancier though, because they are initialized using the SVD results. If you stop here, you’ll get the same test performance as in P1.\n",
    "\n",
    "6. Finetune this network. Now this new network has new parameters to update, i.e. U(l) and V(l) (as well as the bias terms). Update them using BP. Since you initialized the new parameters with SVD, which is a pretty good starting point, you may want to use a smaller-than-usual learning rate.\n",
    "7. Report the test-time classification accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xETZA8nAR02i"
   },
   "source": [
    "#### Extracting the weights from the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7LnxtzJ3QkYc"
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "bias = []\n",
    "for i in range(6):\n",
    "  weights.append(model.layers[i].get_weights()[0])\n",
    "  bias.append(model.layers[i].get_weights()[1])\n",
    "\n",
    "u_upd = [[0]]*5\n",
    "v_upd = [[0]]*5\n",
    "\n",
    "def u_v_svd(mat,D):\n",
    "  s, u, v = tf.linalg.svd(mat,full_matrices=False,compute_uv=True,name=None)\n",
    "  u = u[:,:D]\n",
    "  vh = tf.matmul(tf.linalg.diag(s[:D]), v[:,:D], adjoint_b=True)\n",
    "  return u,vh\n",
    "\n",
    "for i in range(5):\n",
    "  u_upd[i],v_upd[i] = u_v_svd(weights[i], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOCzmcyjScXE"
   },
   "source": [
    "#### Model Architechture \n",
    "Now this model has 10 layers. Each layers in initialized by decomposition matrix u, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxTUfjzGf2Vs"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim = 784,activation=None,name='layer_v1'))\n",
    "model.add(Dense(1024, input_dim = 20,activation='relu',name='layer_u1'))\n",
    "model.add(Dense(20, input_dim = 1024,activation=None,name='layer_v2'))\n",
    "model.add(Dense(1024, input_dim = 20,activation='relu',name='layer_u2'))\n",
    "model.add(Dense(20, input_dim = 1024,activation=None,name='layer_v3'))\n",
    "model.add(Dense(1024, input_dim = 20,activation='relu',name='layer_u3'))\n",
    "model.add(Dense(20, input_dim = 1024,activation=None,name='layer_v4'))\n",
    "model.add(Dense(1024, input_dim = 20,activation='relu',name='layer_u4'))\n",
    "model.add(Dense(20, input_dim = 1024,activation=None,name='layer_v5'))\n",
    "model.add(Dense(1024, input_dim =20 ,activation='relu',name='layer_u5'))\n",
    "model.add(Dense(10, input_dim =1024 ,activation='softmax',name='layer_op'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yXKKAc5pbn1"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_WPwHgdxb-ea",
    "outputId": "b9dfd3d1-9322-4625-9473-009116b51e23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_v1 (Dense)            (None, 20)                15700     \n",
      "                                                                 \n",
      " layer_u1 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " layer_v2 (Dense)            (None, 20)                20500     \n",
      "                                                                 \n",
      " layer_u2 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " layer_v3 (Dense)            (None, 20)                20500     \n",
      "                                                                 \n",
      " layer_u3 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " layer_v4 (Dense)            (None, 20)                20500     \n",
      "                                                                 \n",
      " layer_u4 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " layer_v5 (Dense)            (None, 20)                20500     \n",
      "                                                                 \n",
      " layer_u5 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " layer_op (Dense)            (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,470\n",
      "Trainable params: 215,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vR2-5hJqS9SN"
   },
   "source": [
    "##### Initializing the weights by u and v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUj03g4fS6rI"
   },
   "outputs": [],
   "source": [
    "m = 0\n",
    "n = 0\n",
    "for i in range(10):\n",
    "  if i%2==0:\n",
    "    model.layers[i].set_weights((u_upd[m], bias[m][:20]))\n",
    "    m+=1\n",
    "  else:\n",
    "    model.layers[i].set_weights((v_upd[n],bias[n]))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6YW8rdffiX4O",
    "outputId": "22838af1-2cfb-46d4-82df-c9ca492e92e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5186 - accuracy: 0.8256\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1946 - accuracy: 0.9409\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1437 - accuracy: 0.9555\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1165 - accuracy: 0.9644\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0999 - accuracy: 0.9693\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0852 - accuracy: 0.9735\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0740 - accuracy: 0.9765\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0656 - accuracy: 0.9793\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0581 - accuracy: 0.9820\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0531 - accuracy: 0.9830\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0468 - accuracy: 0.9859\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0423 - accuracy: 0.9866\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0378 - accuracy: 0.9878\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0343 - accuracy: 0.9890\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0333 - accuracy: 0.9893\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0287 - accuracy: 0.9906\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0290 - accuracy: 0.9907\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0258 - accuracy: 0.9920\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0244 - accuracy: 0.9919\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0211 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6d00c6ad0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDeciDYkTF8Y"
   },
   "source": [
    "#### Accuracy in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcUNDl33izdB",
    "outputId": "e4aeb9d3-06fb-4675-c0a7-74e1928eaa27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1291 - accuracy: 0.9734\n",
      "Accuracy: 97.34\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(x_test, y_test )\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4WRVJeuBbes"
   },
   "source": [
    "We compressed the model parameters to 4% of the orginal size without effecting the accuracy much\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zevRRuhTY18"
   },
   "source": [
    "## Problem 3: Network Compression Using SVD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tj4bhvrsbtPw"
   },
   "source": [
    "1. Another way to improve our D = 20 case is to inform the training process of the SVD approximation. It’s a different method from P1, where SVD was performend once after the network training was completed. This time, we do SVD at every epoch.\n",
    "\n",
    "2. Initialize W (l) using the “baseline” model. We will finetune it.\n",
    "\n",
    "3. This time, for the feedforward pass, you never use W(l). Instead, you do SVD at every iteration and\n",
    "make sure the feedforward pass always uses W(l) = U(l) S(l) V (l)⊤ .\n",
    "􏰄 :,1:20 1:20,1:20 :,1:20\n",
    "\n",
    "4. What that means for the training algorithm is that you should think of the low-rank SVD procedure as an approximation function W(l) ≈ f(W(l)) = U(l) S(l) V (l)⊤ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGtop5pOEw7A"
   },
   "source": [
    "##### Storing the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_3LZHP1Z_N5b"
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "bias = []\n",
    "for i in range(6):\n",
    "  weights.append(model.layers[i].get_weights()[0])\n",
    "  bias.append(model.layers[i].get_weights()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zm2gg610yWej"
   },
   "source": [
    "##### Custom gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "8gXdmve1B5p5"
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def weights_custom(weight):\n",
    "    s,u,v = tf.linalg.svd(weights,compute_uv=True,full_matrices=True)\n",
    "    W_hat=tf.matmul(u[:,:20], tf.matmul(tf.linalg.diag(s[:20]), v[:,:20], adjoint_b=True))\n",
    "\n",
    "    def grad(dy):\n",
    "        return tf.gradients(dy, W_hat)\n",
    "    return W_hat, grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipfEjcauydy6"
   },
   "source": [
    "##### Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "EaM5tAEZCEhE"
   },
   "outputs": [],
   "source": [
    "class custom_layer(keras.layers.Layer): #dense\n",
    "\n",
    "     def __init__(self,units,layer_num,input_shape):\n",
    "      super(custom_layer, self).__init__()\n",
    "      self.units=units\n",
    "      self.layer_num = layer_num\n",
    "      self.w=tf.Variable(\n",
    "            initial_value=weights[self.layer_num],\n",
    "            trainable=True,\n",
    "        )\n",
    "      self.b=tf.Variable(\n",
    "            initial_value=bias[self.layer_num],\n",
    "            trainable=True,\n",
    "        )\n",
    "      \n",
    "      def call(self, x):\n",
    "          W_hat=weights_custom(self.w)  \n",
    "          a=keras.activations.relu(tf.matmul(x,W_hat)+self.b)\n",
    "          return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdTKMn7uyi6L"
   },
   "source": [
    "##### Model Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Pn0_PXrMCHib"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(custom_layer(units=1024,input_shape=(784,),layer_num=0))\n",
    "model.add(custom_layer(units=1024,layer_num=1,input_shape=(1024,)))\n",
    "model.add(custom_layer(units=1024,layer_num=2,input_shape=(1024,)))\n",
    "model.add(custom_layer(units=1024,layer_num=3,input_shape=(1024,)))\n",
    "model.add(custom_layer(units=1024,layer_num=4,input_shape=(1024,)))\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "GFHIvzScCHaS"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-CQd0luCYp1",
    "outputId": "55f47e2e-aec3-49b6-9303-5cab4c9576a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "59/59 - 0s - loss: 0.0826 - accuracy: 0.8965 - val_loss: 0.0798 - val_accuracy: 0.9030 - 289ms/epoch - 5ms/step\n",
      "Epoch 2/20\n",
      "59/59 - 0s - loss: 0.0817 - accuracy: 0.8977 - val_loss: 0.0788 - val_accuracy: 0.9036 - 233ms/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "59/59 - 0s - loss: 0.0808 - accuracy: 0.8989 - val_loss: 0.0781 - val_accuracy: 0.9037 - 229ms/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "59/59 - 0s - loss: 0.0800 - accuracy: 0.9002 - val_loss: 0.0774 - val_accuracy: 0.9052 - 238ms/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "59/59 - 0s - loss: 0.0793 - accuracy: 0.9007 - val_loss: 0.0766 - val_accuracy: 0.9054 - 235ms/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "59/59 - 0s - loss: 0.0786 - accuracy: 0.9018 - val_loss: 0.0760 - val_accuracy: 0.9059 - 220ms/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "59/59 - 0s - loss: 0.0780 - accuracy: 0.9029 - val_loss: 0.0754 - val_accuracy: 0.9070 - 244ms/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "59/59 - 0s - loss: 0.0774 - accuracy: 0.9031 - val_loss: 0.0749 - val_accuracy: 0.9072 - 241ms/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "59/59 - 0s - loss: 0.0768 - accuracy: 0.9041 - val_loss: 0.0744 - val_accuracy: 0.9073 - 231ms/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "59/59 - 0s - loss: 0.0763 - accuracy: 0.9046 - val_loss: 0.0739 - val_accuracy: 0.9086 - 241ms/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "59/59 - 0s - loss: 0.0758 - accuracy: 0.9053 - val_loss: 0.0735 - val_accuracy: 0.9081 - 235ms/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "59/59 - 0s - loss: 0.0753 - accuracy: 0.9055 - val_loss: 0.0732 - val_accuracy: 0.9091 - 230ms/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "59/59 - 0s - loss: 0.0749 - accuracy: 0.9064 - val_loss: 0.0727 - val_accuracy: 0.9091 - 261ms/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "59/59 - 0s - loss: 0.0744 - accuracy: 0.9068 - val_loss: 0.0724 - val_accuracy: 0.9092 - 245ms/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "59/59 - 0s - loss: 0.0740 - accuracy: 0.9073 - val_loss: 0.0721 - val_accuracy: 0.9094 - 232ms/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "59/59 - 0s - loss: 0.0737 - accuracy: 0.9079 - val_loss: 0.0717 - val_accuracy: 0.9098 - 223ms/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "59/59 - 0s - loss: 0.0733 - accuracy: 0.9086 - val_loss: 0.0714 - val_accuracy: 0.9101 - 243ms/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "59/59 - 0s - loss: 0.0729 - accuracy: 0.9087 - val_loss: 0.0710 - val_accuracy: 0.9113 - 240ms/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "59/59 - 0s - loss: 0.0726 - accuracy: 0.9093 - val_loss: 0.0708 - val_accuracy: 0.9117 - 243ms/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "59/59 - 0s - loss: 0.0723 - accuracy: 0.9097 - val_loss: 0.0706 - val_accuracy: 0.9116 - 233ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model_hist=model.fit(x=x_train,y=y_train,batch_size=1024,epochs=20,shuffle=True,verbose=2,validation_data=(x_test,y_test)) #(x_train,y_train),(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kqWwJnpyr2T"
   },
   "source": [
    "#### Accuracy in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "blGL8E_aCeYW",
    "outputId": "c4c71901-1682-490e-bd1a-932f9456f19d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0706 - accuracy: 0.9116\n",
      "Accuracy on the test data: 91.16\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(x_test, y_test )\n",
    "print('Accuracy on the test data: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fqzKGDnRCYn"
   },
   "source": [
    "## Problem 4: Speaker Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUAZjo97Dr4q"
   },
   "source": [
    "1. In this problem, we are going to build a speaker verification system. It takes two utterances as input, and predicts whether they were spoken by the same speaker (positive class) or not (negative class).\n",
    "\n",
    "\n",
    "2. trs.pkl contains an 500×16,180 matrix, whose row is a speech signal with 16,180 samples. They are the returned vectors from the librosa.load function. Similarly, tes.pkl holds a 200×22,631 matrix.\n",
    "\n",
    "\n",
    "3. The training matrix is ordered by speakers. Each speaker has 10 utterances, and there are 50 such speakers (that’s why there are 500 rows). Similarly, the test set has 20 speakers, each of which is with 10 utterances.\n",
    "\n",
    "\n",
    "4. Randomly sample L pairs of utterances from the ten utterance of the first speaker. In theory, there are 􏰀10􏰁 = 45 pairs you can sample from (the order of the two utterances within a pair doesn’t matter).\n",
    "You can use all 45 of them if you want. These are the positive examples in your first minibatch.\n",
    "\n",
    "\n",
    "5. Let’s construct L negative pairs as well. First, randomly sample L utterances from the 49 training speakers. Second, randomly sample another L utterances from the first speaker (the speaker you sampled the positive pairs from). Using these two sets, each has L examples, form another set of L pairs. If L > 10, you’ll need to repeatedly use the first speaker’s utterance (i.e. sampling with replacement). This set is your negative examples, each of whose pair contains an utterance from the first speaker and a random utterance spoken by a different speaker.\n",
    "\n",
    "6. The L positive pairs and L negative pairs form your first minibatch. You have 2L pairs of utterances in total.\n",
    "\n",
    "7. Repeat this process for the other training speakers, so that each speaker is represented by L positive pairs and L negative pairs. By doing so, you can form 50 minibatches with a balanced number of positive and negative pairs.\n",
    "\n",
    "8. Train a Siamese network that tries to predict 1 for the positive pairs and 0 for the negative ones. In a minibatch, since you have L positive and L negative pairs, respectively, your net must predict L ones and L zeros, respectively.\n",
    "\n",
    "9. I found that STFT on the signals serves the initial feature extraction process. Therefore, your Siamese network will take as input TWO spectrograms, each of which is of size 513 × T . I wouldn’t care too much about your choice of the network architecture this time (if it works anyway), but it has to somehow predict a fixed-length feature vector for the given sequence of spectra (consequently, TWO fixted-length vectors for the pair of input spectrograms). Using the inner product of the two latent embedding vectors as the input to the sigmoid function, you’ll do a logistic regression. Use your imagination and employ whatever techniques you learned in class to design/train this network.\n",
    "\n",
    "10. Construct similar batches from the test set, and test the verification accuracy of your network. Report your test-time speaker verification performance. I was able to get a decent result (∼ 70%) with a reasonable network architecture (e.g., a GRU working on STFT), which converged in a reasonable amount of time (i.e. in an hour).\n",
    "\n",
    "11. Submit your code and accuracy on the test examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "PV9JAvdCVmMC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout,LSTM, GRU\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import librosa\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGG8zZhrbtO4"
   },
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "0Nnld8I0tbMz"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Deep Learning Assignment/hw4_trs.pkl','rb') as file:\n",
    "  train_data=pickle.load(file)\n",
    "\n",
    "with open('/content/drive/MyDrive/Deep Learning Assignment/hw4_tes.pkl','rb') as file:\n",
    "  test_data=pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6Z8lFnxm0IT"
   },
   "source": [
    "#### Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "nNeGWpPGpxcA"
   },
   "outputs": [],
   "source": [
    "train_spect_mag=[]\n",
    "for i in range(len(train_data)):\n",
    "  train_spect_mag.append(np.abs(librosa.stft(train_data[i], n_fft=1024, hop_length=512)))\n",
    "\n",
    "test_spect_mag=[]\n",
    "for i in range(len(test_data)):\n",
    "  test_spect_mag.append(np.abs(librosa.stft(test_data[i], n_fft=1024, hop_length=512)))\n",
    "\n",
    "train_data=np.array(train_spect_mag)\n",
    "test_data=np.array(test_spect_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USSpmQ7ctvzg",
    "outputId": "cd618e73-9fc5-4dc3-e5ff-cc73fecef9d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 513, 32), (200, 513, 45))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMajVaeim54C"
   },
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "f3IMr8jyTEQN"
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "  input_1=[]\n",
    "  input_2=[]\n",
    "  labels=[]\n",
    "\n",
    "\n",
    "  for i in range(0,len(data),10):\n",
    "    sample1=[i for i in range(i,i+10)]\n",
    "    sample2=[i for i in range(0,i)]+[i for i in range(i+10,len(data))]\n",
    "    index1=np.random.choice(sample1,size=45,replace=True)\n",
    "    index2=np.random.choice(sample1,size=45,replace=True)\n",
    "    index3=np.random.choice(sample1,size=45,replace=True)\n",
    "    index4=np.random.choice(sample2,size=45,replace=False)\n",
    "\n",
    "    x1_pos = data[index1]\n",
    "    x2_pos = data[index2]\n",
    "\n",
    "    x1_neg = data[index3]\n",
    "    x2_neg = data[index4]\n",
    "    if len(input_1)!=0 and len(input_2)!=0 and len(labels)!=0:\n",
    "      input_1=np.concatenate((input_1,x1_pos,x1_neg))\n",
    "      input_2=np.concatenate((input_2,x2_pos,x2_neg))\n",
    "\n",
    "      labels=np.concatenate((labels,np.ones((45,1)),np.zeros((45,1))))  \n",
    "    else:\n",
    "      input_1=np.concatenate((x1_pos,x1_neg))\n",
    "      input_2=np.concatenate((x2_pos,x2_neg))\n",
    "\n",
    "      labels=np.concatenate((np.ones((45,1)),np.zeros((45,1))))    \n",
    "  return input_1,input_2,labels  \n",
    "\n",
    "\n",
    "train_mat_1,train_mat_2,train_labels=data_preprocessing(train_data)\n",
    "test_mat_1,test_mat_2,test_labels=data_preprocessing(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-ThKoZ5nFI2"
   },
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "znvDnnDcVN2-"
   },
   "outputs": [],
   "source": [
    "def siamese_helper_fun(inputShape, embeddingDim=48):\n",
    "  inputs = Input(inputShape)\n",
    "  #x = LSTM(activation='relu',units=128,return_sequences=False,name='layer_1')(inputs)\n",
    "  x = GRU(activation='tanh',units=128,return_sequences=False,name='layer_1')(inputs)\n",
    "  outputs = Dense(units=embeddingDim,activation='relu',kernel_initializer='HeNormal')(x)\n",
    "  model = Model(inputs, outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "u1gKqQ_FnLvO"
   },
   "outputs": [],
   "source": [
    "Input_A = Input((None,513))\n",
    "Input_B = Input((None,513))\n",
    "\n",
    "embeddingsExtractor = siamese_helper_fun((None,513))\n",
    "\n",
    "embedding_A = embeddingsExtractor(Input_A)\n",
    "embedding_B = embeddingsExtractor(Input_B)\n",
    "\n",
    "distance=tf.expand_dims(tf.reduce_sum(tf.multiply(embedding_A, embedding_B),axis=1),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "Jbh-jZolVePq"
   },
   "outputs": [],
   "source": [
    "outputs = Dense(1, activation=\"sigmoid\",kernel_initializer='GlorotNormal')(distance)\n",
    "model = Model(inputs=[Input_A, Input_B], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "O-KjTTNPVeIH"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(),\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "rky2K-uaXoon"
   },
   "outputs": [],
   "source": [
    "train_mat_1=np.transpose(train_mat_1,axes=(0,2,1))\n",
    "train_mat_2=np.transpose(train_mat_2,axes=(0,2,1))\n",
    "test_mat_1=np.transpose(test_mat_1,axes=(0,2,1))\n",
    "test_mat_2=np.transpose(test_mat_2,axes=(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hApEhD3XK9t",
    "outputId": "46f8362b-99e8-40c7-f8d8-b4ac14fd0c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, None, 513)]  0           []                               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, None, 513)]  0           []                               \n",
      "                                                                                                  \n",
      " model_15 (Functional)          (None, 48)           189348      ['input_25[0][0]',               \n",
      "                                                                  'input_26[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 48)          0           ['model_15[0][0]',               \n",
      " )                                                                'model_15[1][0]']               \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_8 (TFOpLamb  (None,)             0           ['tf.math.multiply_8[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_8 (TFOpLambda)  (None, 1)            0           ['tf.math.reduce_sum_8[0][0]']   \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1)            2           ['tf.expand_dims_8[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 189,350\n",
      "Trainable params: 189,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2ajrS8Vqh4z",
    "outputId": "f6ac2764-f086-4fbb-92b3-4051d4a3b1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "36/36 [==============================] - 5s 95ms/step - loss: 0.8242 - accuracy: 0.5311 - val_loss: 0.6898 - val_accuracy: 0.5311\n",
      "Epoch 2/15\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.6778 - accuracy: 0.5611 - val_loss: 0.6847 - val_accuracy: 0.5511\n",
      "Epoch 3/15\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.6782 - accuracy: 0.5718 - val_loss: 0.6886 - val_accuracy: 0.5433\n",
      "Epoch 4/15\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.6720 - accuracy: 0.5718 - val_loss: 0.6863 - val_accuracy: 0.5394\n",
      "Epoch 5/15\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.6597 - accuracy: 0.5871 - val_loss: 0.6799 - val_accuracy: 0.5739\n",
      "Epoch 6/15\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.6408 - accuracy: 0.6240 - val_loss: 0.6690 - val_accuracy: 0.5861\n",
      "Epoch 7/15\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.6448 - accuracy: 0.6129 - val_loss: 0.6789 - val_accuracy: 0.5678\n",
      "Epoch 8/15\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.6259 - accuracy: 0.6387 - val_loss: 0.6717 - val_accuracy: 0.5878\n",
      "Epoch 9/15\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.6155 - accuracy: 0.6620 - val_loss: 0.6646 - val_accuracy: 0.5872\n",
      "Epoch 10/15\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.6061 - accuracy: 0.6693 - val_loss: 0.6927 - val_accuracy: 0.5861\n",
      "Epoch 11/15\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.5784 - accuracy: 0.7100 - val_loss: 0.6527 - val_accuracy: 0.6206\n",
      "Epoch 12/15\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.5653 - accuracy: 0.7280 - val_loss: 0.6535 - val_accuracy: 0.6200\n",
      "Epoch 13/15\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.5451 - accuracy: 0.7609 - val_loss: 0.6537 - val_accuracy: 0.6167\n",
      "Epoch 14/15\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.5311 - accuracy: 0.7702 - val_loss: 0.6731 - val_accuracy: 0.6094\n",
      "Epoch 15/15\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.5301 - accuracy: 0.7693 - val_loss: 0.6397 - val_accuracy: 0.6439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f68c85cc210>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_mat_1, train_mat_2], train_labels,validation_data=([test_mat_1,test_mat_2], test_labels),batch_size=128, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "moc8COhCwIOZ"
   },
   "outputs": [],
   "source": [
    "test_acc=(sum((model.predict([test_mat_1,test_mat_2])>=0.5)==test_labels)/len(test_labels))[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGr0rlBewKcu",
    "outputId": "281d8db3-77dc-47ae-d51b-ef17f527df19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy 64.39\n"
     ]
    }
   ],
   "source": [
    "print(f'Final Test Accuracy {round(test_acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "bBYSn4ayw4uu"
   },
   "outputs": [],
   "source": [
    "model.save_weights('/content/drive/MyDrive/Deep Learning Assignment/siamese',save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnRFe5qKbm_p"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Assignment 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
